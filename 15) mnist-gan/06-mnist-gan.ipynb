{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adverserial Networks in PyTorch\n",
    "\n",
    "Deep neural networks은 주로 분류(classification)나 회귀(regression)와 같은 지도학습에 사용됩니다.\n",
    "하지만, GANs(Generative Adverserial Networks)은 신경망 생성 모델로써 매우 다른 목적으로 사용됩니다.\n",
    "\n",
    "> 생성 적 모델링은 입력 데이터의 규칙이나 패턴을 자동으로 발견하고 학습하는 머신 러닝의 비지도 학습 작업으로, 모델을 사용하여 원래 데이터 세트에서 그럴듯하게 가져올 수있는 새로운 예제를 생성하거나 출력 할 수 있습니다. - [더보기](https://machinelearningmastery.com/what-are-generative-adversarial-networks-gans/)\n",
    "\n",
    "Generative Modeling에 사용되는 접근 방식이 많지만 본 수업에서의 Generative Adversarial Network는 다음 접근 방식을 사용해 보도록 하겠습니다.\n",
    "\n",
    "![GAN Flowchart](https://i.imgur.com/6NMdO9u.png)\n",
    "\n",
    "*Generator*와 *Discriminator*가 있습니다. Generator는 임의의 vector/matrix를 생성하면 \"가짜(fake)\" 샘플을 생성하고, Discriminator는 이를 \"진짜(real)\"(학습에 의한 데이터)인지 \"가짜(fake)\"(Generator에 의한 데이터)인지 분류(Classification)합니다.\n",
    "\n",
    "Generator와 Discriminator는 동시에 학습되는데, 몇 epoch동안 Discriminator를 먼저 학습시키고 나서 Generator를 학습하는 과정을 반복합니다. 이렇게하면 생성자와 판별자가 작업을 더 잘 수행할 수 있습니다.\n",
    "\n",
    "결과는 다음과 같습니다.\n",
    " ([소스](https://machinelearningmastery.com/resources-for-getting-started-with-generative-adversarial-networks/)), 모든 예제는 GAN을 이용했습니다:\n",
    "\n",
    "<img src=\"https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2019/04/Example-of-Photorealistic-Human-Faces-Generated-by-a-GAN.png\" alt=\"gans_results\" width=\"480\">\n",
    "\n",
    "\n",
    "GAN은, 학습이 매우 불안정(unstable)하며, 하이퍼 파라미터에 민감하고, 활성화 함수 및 정규화에 매우 민감합니다. 본 예제에서는, MNIST 데이터셋의 이미지와 유사한 손으로 쓴 숫자의 이미지를 생성하도록 GAN을 훈련해보도록 하겠습니다.\n",
    "\n",
    "<img src=\"https://i.imgur.com/CAYnuo1.jpg\" width=\"360\" >\n",
    "\n",
    "본 코드는 다음 소스를 참고하였습니다: [Reference](https://github.com/yunjey/pytorch-tutorial). "
   ]
  },
  {
   "source": [
    "## 차례\n",
    "* 문제 정의\n",
    "* 데이터로드 (변환 및 정규화, transforms and normalization)\n",
    "    * Denormalize for visual inspection of samples\n",
    "* Discriminator 모델 정의\n",
    "    * 활성화 함수 정의: Leaky ReLU\n",
    "* Generator 모델 정의\n",
    "    * 활성화 함수 정의: TanH\n",
    "    * 출력 샘플 보기\n",
    "* 학습을 위한 손실함수, optimizers와 유용한 함수 정의\n",
    "    * For discriminator\n",
    "    * For generator\n",
    "* 모델 학습\n",
    "    * 중간 생성 이미지 파일 저장\n",
    "* 일부 출력 보기\n",
    "* 모델 저장"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "먼저 'torchvision.datasets'에서 'MNIST' helper class를 사용하여 데이터를 PyTorch 데이터 세트로 다운로드하고 가져옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "mnist = MNIST(root='data', \n",
    "              train=True, \n",
    "              download=True,\n",
    "              transform=Compose([ToTensor(), Normalize(mean=(0.5,), std=(0.5,))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "픽셀 값을 (0, 1) 범위에서 (-1, 1) 범위로 변환하고 있습니다. 이렇게하는 이유는 Generator 모델을 정의할 때 명확해집니다. 데이터에서 샘플 텐서를 살펴 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = mnist[0]\n",
    "print('Label: ', label)\n",
    "print(img[:,10:15,10:15])\n",
    "torch.min(img), torch.max(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예상대로, 픽셀의 범위가 -1에서 1까지입니다. 이미지를 비정규화하고 볼수있는 도우미 함수를 정의하도록 하겠습니다. 이러한 함수는 추후 생성된 Generator에서 이미지를 볼때 유용하게 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denorm(x):\n",
    "    out = (x + 1) / 2\n",
    "    return out.clamp(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "img_norm = denorm(img)\n",
    "plt.imshow(img_norm[0], cmap='gray')\n",
    "print('Label:', label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막으로 이미지를 일괄 적으로로드하는 데이터 로더를 만들어 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 100\n",
    "data_loader = DataLoader(mnist, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_batch, label_batch in data_loader:\n",
    "    print('first batch')\n",
    "    print(img_batch.shape)\n",
    "    plt.imshow(img_batch[0][0], cmap='gray')\n",
    "    print(label_batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용 가능한 경우 데이터와 모델을 GPU로 이동하는데 사용할 수 있는 'device'도 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator 모델\n",
    "\n",
    "Discriminator는 이미지를 입력으로 받아 \"real\"또는 \"generated\"으로 분류하려고합니다. 이런 의미에서 다른 신경망혹은 Encoder와 같습니다(앞에 수업내용 참고!!!). 판별기에 CNN을 사용할 수 있지만 단순히 MLP(Multi Layer Perceptron)을 이용하여 구성하고자 합니다. 각 28x28 이미지를 784 크기의 벡터로 취급합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 784\n",
    "hidden_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,\n",
    "                image_size,\n",
    "                hidden_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.img_sz = image_size\n",
    "        self.hz = hidden_size\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(self.img_sz, self.hz),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(self.hz, self.hz),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(self.hz, 1),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "        \n",
    "D = Discriminator(image_size = image_size,\n",
    "                  hidden_size = hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discriminator에 대해 Leaky ReLU 활성화 함수(activate function)를 사용합니다.\n",
    "\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*ypsvQH7kvtI2BhzR2eT_Sw.png\" width=\"420\">\n",
    "\n",
    "\n",
    ">  일반 ReLU 함수와 달리 Leaky ReLU는 음수 값에 대해 작은 기울기 신호를 전달할 수 있습니다. 결과적으로 Discriminator의 기울기가 Generator로 더 강하게 흐릅니다. 역전파(back-prop) 시 0의 기울기를 전달하는 대신 작은 음(negative)의 기울기를 전달합니다.  - [Source](https://sthalles.github.io/advanced_gans/)\n",
    "\n",
    "\n",
    "다른 이진 분류(binary classification) 모델과 마찬가지로 Discriminator의 출력은 0과 1 사이의 단일 숫자이며 입력 이미지가 가짜(fake) 즉 생성될 가능성으로 해석(분류) 될 수 있습니다.\n",
    "\n",
    "분류 모델을 선택한 장치로 이동해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator 모델\n",
    "\n",
    "The input to the generator is typically a vector or a matrix which is used as a seed for generating an image. \n",
    "Generator에 대한 입력은 일반적으로 이미지 생성을 위한 시드로 사용되는 임의의 백터 또는 행렬 입니다. 다시 한 번, 간단하게 유지하기 위해 3 개의 레이어가있는 피드 포워드 신경망을 사용하고 출력은 28x28 픽셀 이미지로 변환 할 수있는 784 크기의 벡터가됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self,\n",
    "            latent_size,\n",
    "            hidden_size,\n",
    "            image_size):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.ls = latent_size\n",
    "        self.hs = hidden_size\n",
    "        self.img_sz = image_size\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(self.ls, self.hs),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hs, self.hs),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hs, self.img_sz),\n",
    "            nn.Tanh())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "G = Generator(latent_size = latent_size, \n",
    "             hidden_size = hidden_size,\n",
    "             image_size = image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator의 레이어의 출력에 TanH 활성화 함수를 사용하였습니다.\n",
    "\n",
    "<img src=\"https://nic.schraudolph.org/teach/NNcourse/figs/tanh.gif\" width=\"420\" >\n",
    "\n",
    "> \"The ReLU activation  is used in the generator with the exception of the output layer which uses the Tanh function. We observed that using a bounded activation allowed the model to learn more quickly to saturate and cover the color space of the training distribution. Within the discriminator we found the leaky rectified activation (Maas et al., 2013) (Xu et al., 2015) to work well, especially for higher resolution modeling.\" - [Source](https://stackoverflow.com/questions/41489907/generative-adversarial-networks-tanh)\n",
    "\n",
    "\n",
    "TanH 활성화의 출력이 `[-1,1]` 범위에 있기 때문에 학습 데이터 세트의 이미지에 동일한 변환을 적용했습니다. Generator에서  출력 벡터를 생성하고 출력을 변환 및 비정규 화하여 이미지로 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = G(torch.randn(2, latent_size))\n",
    "gen_imgs = denorm(y.reshape((-1, 28,28)).detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(gen_imgs[0], cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(gen_imgs[1], cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "예상 할 수 있듯이 Generator의 출력은 기본적으로 랜덤 노이즈입니다. Generator의 출력 배치를 파일에 저장할 수있는 도우미 함수를 정의해 보겠습니다.\n",
    "\n",
    "Generator를 선택한 device로 이동합시다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator 학습\n",
    "\n",
    "Discriminator는 이진 분류 모델이므로 이진 교차 엔트로피 손실 함수(binary cross entropy loss function)를 사용하여 실제 이미지와 생성 된 이미지를 얼마나 잘 구별 할 수 있는지 정량화 할 수 있습니다.\n",
    "\n",
    "<img src=\"https://image.slidesharecdn.com/chrishokamp-dublinnlp3-160805110319/95/task-based-learning-for-nlp-going-beyond-cross-entropy-chris-hokamp-10-638.jpg?cb=1470395213\" width=\"420\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "d_optimizer = torch.optim.Adam(D.parameters(), lr=0.0002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그래디언트를 재설정하고 판별자를 훈련하는 도우미 함수를 정의해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_grad():\n",
    "    d_optimizer.zero_grad()\n",
    "    g_optimizer.zero_grad()\n",
    "\n",
    "def train_discriminator(images):\n",
    "    # Create the labels which are later used as input for the BCE loss\n",
    "    real_labels = torch.ones(batch_size, 1).to(device)\n",
    "    fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "        \n",
    "    # Loss for real images\n",
    "    outputs = D(images)\n",
    "    d_loss_real = criterion(outputs, real_labels)\n",
    "    real_score = outputs\n",
    "\n",
    "    # Loss for fake images\n",
    "    z = torch.randn(batch_size, latent_size).to(device)\n",
    "    fake_images = G(z)\n",
    "    outputs = D(fake_images)\n",
    "    d_loss_fake = criterion(outputs, fake_labels)\n",
    "    fake_score = outputs\n",
    "\n",
    "    # 로스 합침\n",
    "    d_loss = d_loss_real + d_loss_fake #로스 바뀐거(-아니라 +임!) 주의! 강의자료 보기! \n",
    "    # 기울기 초기화\n",
    "    reset_grad()\n",
    "    # 기울기 계산\n",
    "    d_loss.backward()\n",
    "    # Adjust the parameters using backprop\n",
    "    d_optimizer.step()\n",
    "    \n",
    "    return d_loss, real_score, fake_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 Discriminator를 훈련하는 단계입니다.\n",
    "\n",
    "\n",
    "- 이미지가 실제 MNIST 데이터셋에서 선택되면 Discriminator가 1을 출력하고 0이면 생성된 것이라고 예상한다.\n",
    "\n",
    "- 먼저 실제 이미지 배치를 전달하고, loss를 계산한 다음에, 1로 설정한다.\n",
    "\n",
    "- 그 다음, Generator를 사용하여 가짜 이미지 배치를 생성하고 Discriminator에 전달하고 Loss를 계산하여 대상 레이블을 0으로 설정한다.\n",
    "\n",
    "- 마지막으로 두 손실을 더하고 전체 손실을 경사하강법을 사용하여 Discriminator에 weights를 조정한다.\n",
    "\n",
    "Discriminator를 훈련하는 동안에 Generator의 가중치를 변경하지 않는다는 것을 유의하는것이 중요함!!!!\n",
    "\n",
    "(`d_optimizer` 오직 `D.parameters()`에만 영향을 미침!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator 학습\n",
    "\n",
    "Generator의 출력은 이미지이기 때문에 Generator를 훈련할 수 있는 방법이 명확하지 않습니다.\n",
    "여기에서 Discriminator를 Loss Function의 일부로 사용하는 방법을 사용합니다. 작동 방식은 다음과 같습니다.\n",
    "\n",
    "\n",
    "- Generator를 사용하여 이미지 배치를 생성하고 Discriminator에 전달합니다.\n",
    "\n",
    "- 목표 라벨을 \"1(진짜, real)\"로 설정하여 loss를 계산합니다. Generator의 목적은 Discriminator를 속이는 것이 목적입니다.\n",
    "\n",
    "- Loss를 사용하여 경사하강법을 수행합니다. 즉, Generator의 가중치를 변경하므로 실제와 같은 이미지를 생성하는데 더 유용합니다.\n",
    "\n",
    "다음은 실제 코드 구현입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_optimizer = torch.optim.Adam(G.parameters(), lr=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator():\n",
    "    # Generate fake images and calculate loss\n",
    "    z = torch.randn(batch_size, latent_size).to(device)\n",
    "    fake_images = G(z)\n",
    "    labels = torch.ones(batch_size, 1).to(device)\n",
    "    g_loss = criterion(D(fake_images), labels)\n",
    "\n",
    "    # Backprop and optimize\n",
    "    reset_grad()\n",
    "    g_loss.backward()\n",
    "    g_optimizer.step()\n",
    "    return g_loss, fake_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습\n",
    "\n",
    "모델의 진행 상황을 시각적으로 검사하기 위해 생성기의 중간 출력을 저장할 수있는 디렉토리를 생성하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "sample_dir = 'samples'\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "생성된 이미지를 보면서 시각적 비교에 사용할 수있는 실제 이미지 배치를 저장해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "# Save some real images\n",
    "for images, _ in data_loader:\n",
    "    images = images.reshape(images.size(0), 1, 28, 28)\n",
    "    save_image(denorm(images), os.path.join(sample_dir, 'real_images.png'), nrow=10)\n",
    "    break\n",
    "   \n",
    "Image(os.path.join(sample_dir, 'real_images.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또한 모든 epoch이 끝날 때 생성된 이미지의 배치를 디스크에 저장하는 도우미 함수를 만들어 보겠습니다.\n",
    "Generator에 고정된 특정 seed의 입력 벡터를 사용하여 모델을 학습 할 때 생성 된 개별 이미지가 시간이 지남에 따라 어떻게 진화하는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_vectors = torch.randn(batch_size, latent_size).to(device)\n",
    "\n",
    "def save_fake_images(index):\n",
    "    fake_images = G(sample_vectors)\n",
    "    fake_images = fake_images.reshape(fake_images.size(0), 1, 28, 28)\n",
    "    fake_fname = 'fake_images-{0:0=4d}.png'.format(index)\n",
    "    print('Saving', fake_fname)\n",
    "    save_image(denorm(fake_images), os.path.join(sample_dir, fake_fname), nrow=10)\n",
    "    \n",
    "# Before training\n",
    "save_fake_images(0)\n",
    "Image(os.path.join(sample_dir, 'fake_images-0000.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 모델을 훈련 할 준비가되었습니다. 각 epoch마다 Discriminator를 먼저 훈련시킨 다음 Generator를 훈련시킵니다. GPU를 사용하지 않는 경우 훈련에 시간이 걸릴 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "num_epochs = 300\n",
    "total_step = len(data_loader)\n",
    "d_losses, g_losses, real_scores, fake_scores = [], [], [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, _) in enumerate(data_loader):\n",
    "        # Load a batch & transform to vectors\n",
    "        images = images.reshape(batch_size, -1).to(device)\n",
    "        \n",
    "        # Train the discriminator and generator\n",
    "        d_loss, real_score, fake_score = train_discriminator(images)\n",
    "        g_loss, fake_images = train_generator()\n",
    "        \n",
    "        # Inspect the losses\n",
    "        if (i+1) % 200 == 0:\n",
    "            d_losses.append(d_loss.item())\n",
    "            g_losses.append(g_loss.item())\n",
    "            real_scores.append(real_score.mean().item())\n",
    "            fake_scores.append(fake_score.mean().item())\n",
    "            print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}' \n",
    "                  .format(epoch, num_epochs, i+1, total_step, d_loss.item(), g_loss.item(), \n",
    "                          real_score.mean().item(), fake_score.mean().item()))\n",
    "        \n",
    "    # Sample and save images\n",
    "    save_fake_images(epoch+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 모델을 학습 했으므로 체크 포인트를 저장할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model checkpoints \n",
    "torch.save(G.state_dict(), 'G.ckpt')\n",
    "torch.save(D.state_dict(), 'D.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 10 번째, 50 번째, 100 번째 및 300 번째 교육 epoch 이후 생성 된 이미지의 모습입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('./samples/fake_images-0010.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('./samples/fake_images-0050.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('./samples/fake_images-0100.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('./samples/fake_images-0300.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCV를 사용하여 각 Epoch 이후 생성 된 샘플 이미지를 비디오로 결합하여 훈련 과정을 시각화 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from IPython.display import FileLink\n",
    "\n",
    "vid_fname = 'gans_training.avi'\n",
    "\n",
    "files = [os.path.join(sample_dir, f) for f in os.listdir(sample_dir) if 'fake_images' in f]\n",
    "files.sort()\n",
    "\n",
    "out = cv2.VideoWriter(vid_fname,cv2.VideoWriter_fourcc(*'MP4V'), 8, (302,302))\n",
    "[out.write(cv2.imread(fname)) for fname in files]\n",
    "out.release()\n",
    "FileLink('gans_training.avi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시간이 지남에 따라 손실이 어떻게 변하는지 시각화 할 수도 있습니다. 손실을 시각화하는 것은 훈련 과정을 디버깅하는 데 매우 유용합니다. GAN의 경우 Discriminator의 손실이 너무 높아지지 않고 시간이 지남에 따라 Generator의 손실이 줄어들 것으로 예상합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(d_losses, '-')\n",
    "plt.plot(g_losses, '-')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['Discriminator', 'Generator'])\n",
    "plt.title('Losses');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(real_scores, '-')\n",
    "plt.plot(fake_scores, '-')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('score')\n",
    "plt.legend(['Real Score', 'Fake score'])\n",
    "plt.title('Scores');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('tano': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "df1ebef89fe3587c862adfba157bc52a83d7313f5144167cfdbe9b8c1c95e131"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}